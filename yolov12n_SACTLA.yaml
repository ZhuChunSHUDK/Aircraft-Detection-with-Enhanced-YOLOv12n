# YOLOv12n_lite_attn_highacc_with_TLA.yaml
# Configuration for 14-class aircraft detection task, with increased width to enhance recognition accuracy
# Ensures all ABlock module channels are multiples of 32 for efficient computation

nc: 14  # Number of classes for detection (14 aircraft types)

scales:
  n: [0.50, 0.25, 1024]  # Model scaling parameters: [depth_multiple, width_multiple, max_channels]
  # - depth_multiple (0.50): Reduces the number of layers by 50% to create a lightweight model
  # - width_multiple (0.25): Scales channel counts by 25% to balance performance and efficiency
  # - max_channels (1024): Caps the maximum number of channels to control model size

backbone:
  # Layer 0: Initial spatial attention convolution (SAC) block, downsampling to P1/2
  - [-1, 1, SAC, [64, 3, [1, 3, 5], 2, False]]  # Input: previous layer (-1), 1 repeat, SAC module
  # - Output channels: 64 (multiple of 32)
  # - Kernel size: 3
  # - Kernel sizes for spatial attention: [1, 3, 5]
  # - Stride: 2 (downsamples by 2, creating P1/2 feature map)
  # - Use bias: False (typically used with BatchNorm)

  # Layer 1: SAC block, further downsampling to P2/4
  - [-1, 1, SAC, [128, 3, [1, 3, 5], 2, False]]  # Input: previous layer, 1 repeat, SAC module
  # - Output channels: 128 (multiple of 32)
  # - Kernel size: 3
  # - Kernel sizes for spatial attention: [1, 3, 5]
  # - Stride: 2 (downsamples by 2, creating P2/4 feature map)
  # - Use bias: False

  # Layer 2: C3k2 block for feature extraction
  - [-1, 2, C3k2, [256, False, 0.25]]  # Input: previous layer, 2 repeats, C3k2 module
  # - Output channels: 256 (multiple of 32)
  # - Shortcuts: False (no residual connections)
  # - Bottleneck ratio: 0.25 (reduces internal channels for efficiency)

  # Layer 3: SAC block, downsampling to P3/8
  - [-1, 1, SAC, [256, 3, [1, 3, 5], 2, False]]  # Input: previous layer, 1 repeat, SAC module
  # - Output channels: 256 (multiple of 32)
  # - Kernel size: 3
  # - Kernel sizes for spatial attention: [1, 3, 5]
  # - Stride: 2 (downsamples by 2, creating P3/8 feature map)
  # - Use bias: False

  # Layer 4: C3k2 block for deeper feature extraction
  - [-1, 2, C3k2, [512, False, 0.25]]  # Input: previous layer, 2 repeats, C3k2 module
  # - Output channels: 512 (multiple of 32)
  # - Shortcuts: False
  # - Bottleneck ratio: 0.25

  # Layer 5: SAC block, downsampling to P4/16
  - [-1, 1, SAC, [512, 3, [1, 3, 5], 2, False]]  # Input: previous layer, 1 repeat, SAC module
  # - Output channels: 512 (multiple of 32)
  # - Kernel size: 3
  # - Kernel sizes for spatial attention: [1, 3, 5]
  # - Stride: 2 (downsamples by 2, creating P4/16 feature map)
  # - Use bias: False

  # Layer 6: A2C2f block for advanced feature processing
  - [-1, 4, A2C2f, [512, True, 4]]  # Input: previous layer, 4 repeats, A2C2f module
  # - Output channels: 512 (multiple of 32)
  # - Shortcuts: True (uses residual connections)
  # - Number of attention heads: 4

  # Layer 7: SAC block, downsampling to P5/32
  - [-1, 1, SAC, [1024, 3, [1, 3, 5], 2, False]]  # Input: previous layer, 1 repeat, SAC module
  # - Output channels: 1024 (multiple of 32, capped by max_channels)
  # - Kernel size: 3
  # - Kernel sizes for spatial attention: [1, 3, 5]
  # - Stride: 2 (downsamples by 2, creating P5/32 feature map)
  # - Use bias: False

  # Layer 8: A2C2f block for deep feature processing
  - [-1, 4, A2C2f, [1024, True, 1]]  # Input: previous layer, 4 repeats, A2C2f module
  # - Output channels: 1024 (multiple of 32)
  # - Shortcuts: True
  # - Number of attention heads: 1 (single-head attention for efficiency)

  # Layer 9: TLA (Tiny Layer Attention) module for channel attention
  - [-1, 1, TLA, [512]]  # Input: previous layer, 1 repeat, TLA module
  # - Output channels: 512 (multiple of 32, reduced from 1024 for efficiency)
  # - TLA applies lightweight channel attention to enhance feature focus

head:
  # Layer 10: Upsample to increase resolution
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # Input: previous layer, 1 repeat, Upsample module
  # - Scale factor: 2 (upsamples by 2x using nearest-neighbor interpolation)
  # - Output resolution: Doubles the spatial dimensions (e.g., from P5/32 to P4/16)

  # Layer 11: Concatenate features from layers 10 and 6
  - [[-1, 6], 1, Concat, [1]]  # Inputs: previous layer and layer 6, 1 repeat, Concat module
  # - Concatenates along dimension 1 (channel dimension)
  # - Combines features from different scales for richer representation

  # Layer 12: A2C2f block for feature refinement
  - [-1, 2, A2C2f, [512, False, -1]]  # Input: previous layer, 2 repeats, A2C2f module
  # - Output channels: 512 (multiple of 32)
  # - Shortcuts: False
  # - Number of attention heads: -1 (default, typically matches input channels)

  # Layer 13: Upsample to further increase resolution
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # Input: previous layer, 1 repeat, Upsample module
  # - Scale factor: 2 (upsamples by 2x, e.g., from P4/16 to P3/8)
  # - Uses nearest-neighbor interpolation

  # Layer 14: Concatenate features from layers 13 and 4
  - [[-1, 4], 1, Concat, [1]]  # Inputs: previous layer and layer 4, 1 repeat, Concat module
  # - Concatenates along channel dimension to fuse multi-scale features

  # Layer 15: A2C2f block for further feature processing
  - [-1, 2, A2C2f, [256, False, -1]]  # Input: previous layer, 2 repeats, A2C2f module
  # - Output channels: 256 (multiple of 32)
  # - Shortcuts: False
  # - Number of attention heads: -1 (default)

  # Layer 16: SAC block for spatial attention
  - [-1, 1, SAC, [256, 3, [1, 3, 5], 2, False]]  # Input: previous layer, 1 repeat, SAC module
  # - Output channels: 256 (multiple of 32)
  # - Kernel size: 3
  # - Kernel sizes for spatial attention: [1, 3, 5]
  # - Stride: 2 (downsamples by 2)
  # - Use bias: False

  # Layer 17: TLA module for channel attention
  - [-1, 1, TLA, [256]]  # Input: previous layer, 1 repeat, TLA module
  # - Output channels: 256 (multiple of 32)
  # - Enhances feature focus using lightweight channel attention

  # Layer 18: Concatenate features from layers 17 and 11
  - [[-1, 11], 1, Concat, [1]]  # Inputs: previous layer and layer 11, 1 repeat, Concat module
  # - Concatenates along channel dimension for multi-scale feature fusion

  # Layer 19: A2C2f block for final feature refinement
  - [-1, 2, A2C2f, [512, False, -1]]  # Input: previous layer, 2 repeats, A2C2f module
  # - Output channels: 512 (multiple of 32)
  # - Shortcuts: False
  # - Number of attention heads: -1 (default)

  # Layer 20: SAC block for spatial attention
  - [-1, 1, SAC, [512, 3, [1, 3, 5], 2, False]]  # Input: previous layer, 1 repeat, SAC module
  # - Output channels: 512 (multiple of 32)
  # - Kernel size: 3
  # - Kernel sizes for spatial attention: [1, 3, 5]
  # - Stride: 2 (downsamples by 2)
  # - Use bias: False

  # Layer 21: Concatenate features from layers 20 and 8
  - [[-1, 8], 1, Concat, [1]]  # Inputs: previous layer and layer 8, 1 repeat, Concat module
  # - Concatenates along channel dimension for deep feature fusion

  # Layer 22: C3k2 block for final feature processing
  - [-1, 2, C3k2, [1024, True]]  # Input: previous layer, 2 repeats, C3k2 module
  # - Output channels: 1024 (multiple of 32)
  # - Shortcuts: True (uses residual connections for better gradient flow)

  # Layer 23: Detection head
  - [[14, 19, 22], 1, Detect, [nc]]  # Inputs: layers 14, 19, 22, 1 repeat, Detect module
  # - Number of classes: nc (14)
  # - Combines multi-scale features for final detection output
